#Import necessary libraries 
import tensorflow as tf
import numpy as np 
from sklearn.datasets import load_iris 
from sklearn.model_selection import train_test_split 
from sklearn.preprocessing import LabelBinarizer 
 
# Load Iris dataset 
iris = load_iris() 
 
# Get features and output 
X = iris.data 
y = iris.target 
 
# One-hot encode labels 
lb = LabelBinarizer() 
y = lb.fit_transform(y) 
 
# Split data into train and test sets 
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42) 
 
# Define model architecture 
model = tf.keras.Sequential([ 
tf.keras.layers.Dense(16, input_shape=(4,), activation='relu'), tf.keras.layers.Dense(8, activation='relu'), tf.keras.layers.Dense(3, activation='softmax')]) 
 
# Define a list of optimizers to use 
optimizers = ['sgd', 'adam', 'rmsprop'] 
 
# Loop over each optimizer and compile, train, and evaluate the model 
for optimizer in optimizers:     
  model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy']) 
  history = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=50, verbose=0) 
  # Evaluate the model on the test set     
  loss, accuracy = model.evaluate(X_test, y_test, verbose=0)     # Print the optimizer, test loss, and test accuracy    
  print('Optimizer:', optimizer)     
  print('Test loss:', loss)      
  print('Test accuracy:', accuracy) 



#Import necessary libraries 
import tensorflow as tf 
import numpy as np 
from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split 
from sklearn.preprocessing import LabelBinarizer 
 
# Load Iris dataset
iris = load_iris() 
X = iris.data 
y = iris.target 
 
# One-hot encode labels 
lb = LabelBinarizer() 
y = lb.fit_transform(y) 
 
# Split data into train and test sets 
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42) 
 
# Define model architecture
model = tf.keras.Sequential([ tf.keras.layers.Dense(16, input_shape=(4,), activation='relu'),tf.keras.layers.Dense(8, activation='relu'), tf.keras.layers.Dense(3, activation='softmax')]) 
 
# Compile model with different optimizers 
optimizers = ['sgd', 'adam', 'rmsprop']
for optimizer in optimizers:
  model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])     
  history = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=50, verbose=0) 
 
    # Evaluate model 
  loss, accuracy = model.evaluate(X_test, y_test, verbose=0) 
  print('Optimizer:', optimizer)     
  print('Test loss:', loss)    
  print('Test accuracy:', accuracy) 
 
# Allow user to input values for the flower attributes 
  print('\nInput values for the flower attributes:')
  sepal_length = float(input('Sepal length (cm): ')) 
  sepal_width = float(input('Sepal width (cm): ')) 
  petal_length = float(input('Petal length (cm): ')) 
  petal_width = float(input('Petal width (cm): ')) 
  input_values = np.array([[sepal_length, sepal_width, petal_length, petal_width]])
  prediction = model.predict(input_values)
  predicted_class = np.argmax(prediction) 
  class_names = iris.target_names
  print('\nPredicted class: ', class_names[predicted_class]) 


#Import necessary libraries
import tensorflow as tf 
import numpy as np
from sklearn.datasets import load_iris 
from sklearn.model_selection import train_test_split 
from sklearn.preprocessing import LabelBinarizer 
 
# Load Iris dataset
iris = load_iris()
X = iris.data 
y = iris.target 
 
# One-hot encode labels 
lb = LabelBinarizer() 
y = lb.fit_transform(y) 
 
# Split data into train and test sets 
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42) 
 
# Define model architecture
model = tf.keras.Sequential([ tf.keras.layers.Dense(16, input_shape=(4,),activation='relu'),tf.keras.layers.Dense(8, activation='relu'), tf.keras.layers.Dense(3, activation='softmax') ])  
# Define dictionary of optimizers 
optimizers = { 'sgd': tf.keras.optimizers.SGD(), 'adam': tf.keras.optimizers.Adam(),'rmsprop': tf.keras.optimizers.RMSprop() } 
 
# Compile model with different optimizers 
for optimizer_name, optimizer in optimizers.items():     
  model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])     
  history = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=50, verbose=0)    
  loss, accuracy = model.evaluate(X_test, y_test, verbose=0)     
  print('Optimizer:', optimizer_name) 
  print('Test loss:', loss)     
  print('Test accuracy:', accuracy) 
  # Estimate memory requirement 
  size_in_bytes = model.count_params() * 4  # each parameter is a 32-bit float     
  size_in_mb = size_in_bytes / (1024 * 1024) 
  print(f'Memory requirement: {size_in_mb:.2f} MB') 
  

  
